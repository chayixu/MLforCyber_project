{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "repair.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "05YEgJrQcFOy"
      },
      "source": [
        "import keras\n",
        "import h5py\n",
        "import numpy as np\n",
        "import keras.backend as K"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5SHK7HLcIlk"
      },
      "source": [
        "def data_loader(filepath):\n",
        "    data = h5py.File(filepath, 'r')\n",
        "    x_data = np.array(data['data'])\n",
        "    y_data = np.array(data['label'])\n",
        "    x_data = x_data.transpose((0,2,3,1))\n",
        "    return x_data, y_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8GPj3_Pc0kA"
      },
      "source": [
        "def data_preprocess(x_data):\n",
        "    return x_data/255"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oR5DBYHbDfh"
      },
      "source": [
        "def score(x,y,model):\n",
        "  clean_label_p = np.argmax(model.predict(x), axis=1)\n",
        "  class_accu = np.mean(np.equal(clean_label_p, y))*100\n",
        "  print('Classification accuracy:', class_accu)\n",
        "  return class_accu"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWuWQqjqWBW6"
      },
      "source": [
        "load all the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0QwxWJJWDyi"
      },
      "source": [
        "x_clean_test, y_clean_test = data_loader(\"drive/MyDrive/data/clean_test_data.h5\")\n",
        "x_clean_test = data_preprocess(x_clean_test)\n",
        "x_clean_val, y_clean_val = data_loader(\"drive/MyDrive/data/clean_validation_data.h5\")\n",
        "x_clean_val = data_preprocess(x_clean_val)\n",
        "x_sunglass_poison, y_sunglass_poison = data_loader(\"drive/MyDrive/data/sunglasses_poisoned_data.h5\")\n",
        "x_sunglass_poison = data_preprocess(x_sunglass_poison)\n",
        "x_anonymous, y_anonymous = data_loader(\"drive/MyDrive/data/anonymous_1_poisoned_data.h5\")\n",
        "x_anonymous = data_preprocess(x_anonymous)\n",
        "x_eyebrows, y_eyebrows = data_loader(\"drive/MyDrive/data/eyebrows_poisoned_data.h5\")\n",
        "x_eyebrows = data_preprocess(x_eyebrows)\n",
        "x_lipstick, y_lipstick = data_loader(\"drive/MyDrive/data/lipstick_poisoned_data.h5\")\n",
        "x_lipstick = data_preprocess(x_lipstick)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phyiv6ObzIib"
      },
      "source": [
        "repair functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX2uR4jvRLwC"
      },
      "source": [
        "def deleteWeight(weights, index):\n",
        "  #return two lists of weights, weight_choice and bias_choice\n",
        "  #choice[0] is the original weights of the net\n",
        "  #choice[i] is the weights after deleting i nodes by index\n",
        "  #maximum of i is 60 (total 60 nodes in conv_3 layer)\n",
        "\n",
        "  node_weight = np.array(weights[4])#original weights\n",
        "  bias_weight = np.array(weights[5])#original bias\n",
        "\n",
        "  weight_choice = []\n",
        "  weight_choice.append(node_weight)\n",
        "  bias_choice = []\n",
        "  bias_choice.append(bias_weight)\n",
        "  for i in range(60):\n",
        "    temp = np.array(weight_choice[-1])\n",
        "    temp[:,:,:,index[i]] = 0   #set weights 0\n",
        "    weight_choice.append(temp)\n",
        "    temp2 = np.array(bias_choice[-1])\n",
        "    temp2[index[i]] = 0   #set bias 0\n",
        "    bias_choice.append(temp2)\n",
        "  \n",
        "  return weight_choice, bias_choice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Z7zOyLUnVs"
      },
      "source": [
        "def prune(badnetModel, weight_choice, bias_choice):\n",
        "  model = badnetModel\n",
        "  new_weights = np.array(model.get_weights())\n",
        "  new_weights[4] = weight_choice[50]  #update new weights\n",
        "  new_weights[5] = bias_choice[50]   #update new bias\n",
        "  model.set_weights(new_weights)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fIE10cfVfbG"
      },
      "source": [
        "def retrain(prunedModel, x_val, y_val):\n",
        "  model = prunedModel\n",
        "\n",
        "  layer = model.get_layer(name='conv_3')\n",
        "  layer.trainable = False\n",
        "  layer = model.get_layer(name='pool_3')\n",
        "  layer.trainable = False\n",
        "  opt = keras.optimizers.Adadelta(learning_rate=1)\n",
        "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(optimizer=opt, loss=loss)\n",
        "  model.fit(x_clean_val,y_clean_val, epochs=10, batch_size=32)\n",
        " # opt = keras.optimizers.Adadelta(learning_rate=0.1)\n",
        " ## model.compile(optimizer=opt, loss=loss)\n",
        "  #model.fit(x_clean_val,y_clean_val, epochs=5, batch_size=32)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU9BjR-zt6oE"
      },
      "source": [
        "def repair(badnetModel, x_val, y_val):\n",
        "  repairedModel = badnetModel\n",
        "  x = x_val\n",
        "  y = y_val\n",
        "\n",
        "  #getting the output from 'pool_3' layer\n",
        "  function = keras.backend.function(badnetModel.inputs, badnetModel.get_layer('pool_3').output)\n",
        "  pool_3_output = function(x_val)\n",
        "  #calculate the mean activation of each node\n",
        "  activation = np.mean(pool_3_output, axis=(0,1,2))\n",
        "  #get a list of node index by activation increasing order\n",
        "  index = np.argsort(activation)\n",
        "\n",
        "  #get the weights and bias lists after each deletion\n",
        "  weight_choice, bias_choice = deleteWeight(badnetModel.get_weights(), index)\n",
        "  #prune the model\n",
        "  repairedModel = prune(repairedModel, weight_choice, bias_choice)\n",
        "  #retrain the model with validation set\n",
        "  repairedModel = retrain(repairedModel, x_val, y_val)\n",
        "\n",
        "  return repairedModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZuZTiSyd1ic"
      },
      "source": [
        "repair bad net models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3MSDOx5d5Zc"
      },
      "source": [
        "#sunglasses_repaired = repair(keras.models.load_model(\"/content/drive/MyDrive/models/sunglasses_bd_net.h5\"), x_clean_val, y_clean_val)\n",
        "#sunglasses_repaired.save(\"/content/drive/MyDrive/repaired models/sunglasses_repaired.h5\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdbNKrUAjpVc"
      },
      "source": [
        "#anonymous_1_repaired = repair(keras.models.load_model(\"/content/drive/MyDrive/models/anonymous_1_bd_net.h5\"), x_clean_val, y_clean_val)\n",
        "#anonymous_1_repaired.save(\"/content/drive/MyDrive/repaired models/anonymous_1_repaired.h5\")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R8kjyWzj9rj"
      },
      "source": [
        "#anonymous_2_repaired = repair(keras.models.load_model(\"/content/drive/MyDrive/models/anonymous_2_bd_net.h5\"), x_clean_val, y_clean_val)\n",
        "#anonymous_2_repaired.save(\"/content/drive/MyDrive/repaired models/anonymous_2_repaired.h5\")"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmJqRlDED6Mw"
      },
      "source": [
        "#multi_trigger_repaired = repair(keras.models.load_model(\"/content/drive/MyDrive/models/multi_trigger_multi_target_bd_net.h5\"), x_clean_val, y_clean_val)\n",
        "#multi_trigger_repaired.save(\"/content/drive/MyDrive/repaired models/multi_trigger_repaired.h5\")"
      ],
      "execution_count": 70,
      "outputs": []
    }
  ]
}